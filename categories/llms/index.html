<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>LLMs | Loong&#39;s Lens</title>
<meta name="keywords" content="">
<meta name="description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://diqiuzhuanzhuan.github.io/categories/llms/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.755375f2d2f5befc89390aa1da6369388945ce457429a284ad9ed354197440d0.css" integrity="sha256-dVN18tL1vvyJOQqh2mNpOIlFzkV0KaKErZ7TVBl0QNA=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://diqiuzhuanzhuan.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://diqiuzhuanzhuan.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://diqiuzhuanzhuan.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://diqiuzhuanzhuan.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://diqiuzhuanzhuan.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://diqiuzhuanzhuan.github.io/categories/llms/index.xml">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>

<meta property="og:title" content="LLMs" />
<meta property="og:description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://diqiuzhuanzhuan.github.io/categories/llms/" /><meta property="og:image" content="https://diqiuzhuanzhuan.github.io/images/papermod-cover.png"/>


<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://diqiuzhuanzhuan.github.io/images/papermod-cover.png"/>

<meta name="twitter:title" content="LLMs"/>
<meta name="twitter:description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"/>

</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://diqiuzhuanzhuan.github.io/" accesskey="h" title="Loong&#39;s Lens (Alt + H)">Loong&#39;s Lens</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://diqiuzhuanzhuan.github.io/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://diqiuzhuanzhuan.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://diqiuzhuanzhuan.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://diqiuzhuanzhuan.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header"><div class="breadcrumbs"><a href="https://diqiuzhuanzhuan.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://diqiuzhuanzhuan.github.io/categories/">Categories</a></div>
  <h1>
    LLMs
    <a href="/categories/llms/index.xml" title="RSS" aria-label="RSS">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
        stroke-linecap="round" stroke-linejoin="round" height="23">
        <path d="M4 11a9 9 0 0 1 9 9" />
        <path d="M4 4a16 16 0 0 1 16 16" />
        <circle cx="5" cy="19" r="1" />
      </svg>
    </a>
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">LLM deploy
    </h2>
  </header>
  <div class="entry-content">
    <p></p>
  </div>
  <footer class="entry-footer"><span title='2024-04-23 00:00:00 +0000 UTC'>April 23, 2024</span>&nbsp;·&nbsp;0 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to LLM deploy" href="https://diqiuzhuanzhuan.github.io/posts/llm-deploy/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">RAG
    </h2>
  </header>
  <div class="entry-content">
    <p>Rewrite-Retrieve-Read This work introduces a new framework, Rewrite-Retrieve-Read1 instead of the previous retrieve-then-read for the retrieval-augmented LLMs from the perspective of the query rewriting. In this framework, a small language model is adopted as a trainable rewriter to cater to the downstream LLM. Figure 1. Overview of proposed pipeline. (a) standard retrieve-then-read method. (b) LLM as a query rewriter. (c) pipeline with a trainable writer. (Image source: (Query Rewriting for Retrieval-Augmented Large Language Models))...</p>
  </div>
  <footer class="entry-footer"><span title='2024-02-23 00:00:00 +0000 UTC'>February 23, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to RAG" href="https://diqiuzhuanzhuan.github.io/posts/retrieval-augoment-generation/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">LLM Inference
    </h2>
  </header>
  <div class="entry-content">
    <p>why LLM inference runs slowly excellent solutions cerebras Figure 1. The result of LLaMA3.1-70B inference speed with different solutions. (Image source: Artificial Analysis)</p>
  </div>
  <footer class="entry-footer"><span title='2024-02-22 00:00:00 +0000 UTC'>February 22, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to LLM Inference" href="https://diqiuzhuanzhuan.github.io/posts/llm-inference/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Align LLMs
    </h2>
  </header>
  <div class="entry-content">
    <p>After pretraining on vast datasets and supervised fine-tuning with diverse instruction sets, Large Language Models (LLMs) have achieved remarkable capabilities in text generation. However, LLMs can generate seemingly reasonable sequences—-free from grammatical errors and redundant words—-they may still generate content that lacks truthfulness or accuracy. Are there any methods to mitigate these shortcomings? Researchers at OpenAI have framed these issues as the challenge of LLM alignment. Currently, one of the most prominent approaches to address these challenges is Reinforcement Learning from Human Feedback (RLHF)....</p>
  </div>
  <footer class="entry-footer"><span title='2024-01-23 00:00:00 +0000 UTC'>January 23, 2024</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Align LLMs" href="https://diqiuzhuanzhuan.github.io/posts/align-llms/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Audio LLMs
    </h2>
  </header>
  <div class="entry-content">
    <p>audioLM Based on SoundStream1 and w2v-BERT2, audioLM3 proposes a framework which consist of three components: tokenizer model, decoder-only Transformer language model, detokenizer model. SoundStream, is neural audio codec with strong performance, which converts input waveforms at 16 kHZ into embeddings while w2v-BERT plays the role to compute semantic tokens. Figure 1. (Image source: AudioLM: a Language Modeling Approach to Audio Generation)
Figure 2. The three stages of the hierarchical modeling of semantic and acoustic tokens in AudioLM: i) semantic modeling for long-term structural coherence, ii) coarse acoustic modeling conditioned on the semantic tokens and iii) fine acoustic modeling....</p>
  </div>
  <footer class="entry-footer"><span title='2024-01-23 00:00:00 +0000 UTC'>January 23, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Audio LLMs" href="https://diqiuzhuanzhuan.github.io/posts/audio-llms/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">LLM Agent
    </h2>
  </header>
  <div class="entry-content">
    <p>open-source component memo: A memory module of AI Agent for memorizing personal preferences, previous interactions, and business stages.</p>
  </div>
  <footer class="entry-footer"><span title='2024-01-23 00:00:00 +0000 UTC'>January 23, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to LLM Agent" href="https://diqiuzhuanzhuan.github.io/posts/llm-agent/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Prompt Engineering with LLMs
    </h2>
  </header>
  <div class="entry-content">
    <p> LOT-exp1.png LOT-exp2.png </p>
  </div>
  <footer class="entry-footer"><span title='2024-01-11 00:00:00 +0000 UTC'>January 11, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;author: Loong</footer>
  <a class="entry-link" aria-label="post link to Prompt Engineering with LLMs" href="https://diqiuzhuanzhuan.github.io/posts/prompt-engineering/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Data for LLMs
    </h2>
  </header>
  <div class="entry-content">
    <p>Training an LLM needs a large amount of high qualitity data. Even though many giant teches open up their high performance LLMs (e.g., LLaMA, Mistral), high qualitity data still remain private.
Chinese Dataset English Dataset RefinedWeb: 600 B toknes
Dolma: open-sourced by allenai, contains 3T tokens and a toolkit with some key features: high performance, portability, built-in tagger, fast decuplication, extensibility and cloud support.
fineweb: 15 trillion tokens of high quality web data....</p>
  </div>
  <footer class="entry-footer"><span title='2024-01-04 00:00:00 +0000 UTC'>January 4, 2024</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Data for LLMs" href="https://diqiuzhuanzhuan.github.io/posts/data-manager-for-llms/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Continual Pretraining
    </h2>
  </header>
  <div class="entry-content">
    <p>Large language models (LLMs) have already demonstrated significant achievements, many startups make a plan to train their own LLMs. However, training a LLM from scratch remains a big challenge, both in terms of machine costs and the difficulty of data collection. Under this background, continuous pretraining based on some open source LLMs is a considerable alternative.
Determine your purpose of your continuous pretraining LLM. In common, standard LLMs may not excel in specific domains like financial, law, or trade....</p>
  </div>
  <footer class="entry-footer"><span title='2023-12-29 00:00:00 +0000 UTC'>December 29, 2023</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Continual Pretraining" href="https://diqiuzhuanzhuan.github.io/posts/continuous-pretraining/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Image Generation
    </h2>
  </header>
  <div class="entry-content">
    <p>GLIDE </p>
  </div>
  <footer class="entry-footer"><span title='2023-12-11 00:00:00 +0000 UTC'>December 11, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Image Generation" href="https://diqiuzhuanzhuan.github.io/posts/image-generation/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Video Generation
    </h2>
  </header>
  <div class="entry-content">
    <p>Recently, numerous AGI applications catch the eyes of almost all the people on the internet. Here lists some advanced papers elucidate their key principles and technologies.
DiT The authors explore a new class of diffusion models based on the transformer architecture, Diffusion Transformers (DITs)1. Before their work, using a U-Net backbone to generate the target image is prevalent instead of using a transformer architecture. The authors make some experiments with variants of standard transformer blocks that incorporate conditioning via adaptive layer norm, cross-attention and extra input tokens....</p>
  </div>
  <footer class="entry-footer"><span title='2023-12-11 00:00:00 +0000 UTC'>December 11, 2023</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;author: Loong</footer>
  <a class="entry-link" aria-label="post link to Video Generation" href="https://diqiuzhuanzhuan.github.io/posts/video-generation/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Problems you may encounter during distributed training
    </h2>
  </header>
  <div class="entry-content">
    <p>Large Language Models (LLMs) have show great promise in various artificial intelligence applications. It is becoming a trend to train a Large Language Model. Nevertheless even for many senior AI engineers, training these complex models remain a significant challenge. Here lists a series of issues you may encounter in the future.
torch.distributed.barrier() stuck during training with multi gpus At first, you should try to set the environment variable ‘NCCL_P2P_DISABLE=1’. If it works out, the solution is probably to disable ACS of Pcie in BIOS....</p>
  </div>
  <footer class="entry-footer"><span title='2023-08-11 00:00:00 +0000 UTC'>August 11, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;author: Loong</footer>
  <a class="entry-link" aria-label="post link to Problems you may encounter during distributed training" href="https://diqiuzhuanzhuan.github.io/posts/problems-you-may-encounter-while-distributed-training/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Evolution of Multimodality
    </h2>
  </header>
  <div class="entry-content">
    <p>With the swift development of deep neural networks, a multitude of models handling diverse information modalities like text, speech, images, and videos have proliferated. Among AI researchers, it’s widely acknowledged that multimodality is the future of AI. Let’s explore the advancements in multimodality in recent years.
Texts &amp; Images CLIP CLIP (radford et al., 20211) thinks learning directly from raw text about images is promising alternative which leverage much a boarder source of supervision....</p>
  </div>
  <footer class="entry-footer"><span title='2023-04-22 00:00:00 +0000 UTC'>April 22, 2023</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Evolution of Multimodality" href="https://diqiuzhuanzhuan.github.io/posts/evolution-of-multimodality/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Positional Encoding in Transformer
    </h2>
  </header>
  <div class="entry-content">
    <p>With the advancement of large language models (LLMs), the significance of the context length they can handle is increasingly apparent. Let’s take a look at the evolution of positional encoding over the years to enhance the context processing capability of LLMs.
Vanilla Positional Encoding Why does Transformer need positional encoding? Actually, Transformer contains no recurrence and no convolution. To help the model to ultilize the order of the sequence, Vanilla Transformer (vaswani et al....</p>
  </div>
  <footer class="entry-footer"><span title='2023-03-10 00:00:00 +0000 UTC'>March 10, 2023</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Positional Encoding in Transformer" href="https://diqiuzhuanzhuan.github.io/posts/position-encoding-in-transformers/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Know about diffusion models
    </h2>
  </header>
  <div class="entry-content">
    <p>What Is Generative Models? A generative model can be seen as a way to model the conditional probability of the observed $X$ given a target $y$ (e.g., given a target ‘dog’, generate a picture of the dog). Once trained, we can easily sample a stance of $X$. While training a generative model is significantly more challenging than a discriminative model (e.g., it is more difficult to generate an image of a dog than to identify a dog in a picture), it offers the ability to create entirely new data....</p>
  </div>
  <footer class="entry-footer">3 min&nbsp;·&nbsp;Loong</footer>
  <a class="entry-link" aria-label="post link to Know about diffusion models" href="https://diqiuzhuanzhuan.github.io/posts/know-about-diffusion-models/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="https://diqiuzhuanzhuan.github.io/categories/llms/page/2/">Next&nbsp;2/2&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://diqiuzhuanzhuan.github.io/">Loong&#39;s Lens</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
